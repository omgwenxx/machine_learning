{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All imports needed\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import neighbors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Visualizations\n",
    "\n",
    "Dataset used: [Real Estate dataset](http://archive.ics.uci.edu/ml/datasets/Real+estate+valuation+data+set)\n",
    "\n",
    "##### Features:\n",
    "* transcation date: the transaction date (for example, 2013.250=2013 March, 2013.500=2013 June, etc.)\n",
    "* house age: the house age (unit: year)\n",
    "* MRT distance: the distance to the nearest MRT station (unit: meter)\n",
    "* number of stores: the number of convenience stores in the living circle on foot (integer)\n",
    "* latitude: the geographic coordinate, latitude. (unit: degree)\n",
    "* longitude: the geographic coordinate, longitude. (unit: degree)\n",
    "\n",
    "The output is as follow\n",
    "* price: house price of unit area (10000 New Taiwan Dollar/Ping, where Ping is a local unit, 1 Ping = 3.3 meter squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from file\n",
    "real_estate = pd.read_csv(\"../data/metro/metro.csv\") \n",
    "original_data = real_estate.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data exploration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original_data.info()\n",
    "# original_data.describe()\n",
    "# original_data.hist(figsize=(8,8))\n",
    "# original_data.boxplot()\n",
    "# original_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing:\n",
    "As the data set has a column of dates which is a float value, we decided it might increas the prediction quality if we separate according to the month and year. The value after the decimal point represents the month. Taking 100 divided by 12 (12 months) its values is the corresponding month if the valued is diveded by 100/12.\n",
    "We are going to test regression with different preprocessed datasets:\n",
    "\n",
    "* original_data: imported from the csv file, without any preprocessing\n",
    "* real_estate: transaction date splitted into transaction year and month (additional columns)\n",
    "\n",
    "To try out scaling, we decided (due to the fact that not all values are normally distributed) to try RobustScaling and MinMaxScaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing date\n",
    "# transaction_date = real_estate['transaction date'].astype(str).str.split('.', n = 1, expand = True)\n",
    "# real_estate['transaction year'] = real_estate['transaction date'].apply(np.floor)\n",
    "# real_estate['transaction month'] = (((abs(real_estate['transaction date']-real_estate['transaction year']))*1000)/83).round()\n",
    "# real_estate = real_estate.drop(columns=['transaction date'])\n",
    "# real_estate.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modeling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polynomial_regression(X_train, X_test, y_train, degree = 2):\n",
    "    poly = PolynomialFeatures(degree)\n",
    "    x_poly = poly.fit_transform(X_train)\n",
    "    \n",
    "    model = LinearRegression()\n",
    "    model.fit(x_poly, y_train)\n",
    "    \n",
    "    y_pred = model.predict(poly.fit_transform(X_test))\n",
    "    return y_pred\n",
    "\n",
    "def plot_scatter(y_test, y_pred):\n",
    "    # Plot outputs\n",
    "    plt.scatter(y_test, y_pred)\n",
    "\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def print_performance(y_test, y_pred):\n",
    "    # Mean Squared Error\n",
    "    print(\"MSE: \", metrics.mean_squared_error(y_test,y_pred))\n",
    "    \n",
    "    print(\"RMSE: \", metrics.mean_squared_error(y_test,y_pred, squared=False))\n",
    "    \n",
    "    # R2 is between 0 and 100 percent\n",
    "    # 0 indicates that the model explains none of the variability of the response data around its mean.\n",
    "    # 100 indicates that the model explains all the variability of the response data around its mean.\n",
    "    print(\"R2: \", metrics.r2_score(y_test,y_pred) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting parameters for testing\n",
    "# regression models\n",
    "alpha = [0.1,0.9,1,2,4]\n",
    "normalize = [True, False]\n",
    "degrees = [2,3]\n",
    "\n",
    "# knn\n",
    "n_neighbour = [2, 5, 8, 12] \n",
    "weights = ['uniform', 'distance']\n",
    "\n",
    "# trees\n",
    "tree_max_depth = [6, 9, 12, 15]\n",
    "tree_min_split = [3, 6, 9, 12]\n",
    "forest_n_estimators = [10, 50, 75]\n",
    "forest_max_depth = [6, 9, 12, 15, 20]\n",
    "forest_min_split = [2, 5] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression\n",
      "MSE:  3319895.787575414\n",
      "RMSE:  1822.0581186052805\n",
      "R2:  15.880656681245597\n",
      "\n",
      "Lasso Regression\n",
      "{'alpha': 0.1, 'normalize': False}\n",
      "MSE:  3320015.0595705356\n",
      "RMSE:  1822.0908483307126\n",
      "R2:  15.877634573761522\n",
      "\n",
      "Ridge Regression\n",
      "{'alpha': 2, 'normalize': False}\n",
      "MSE:  3319868.602081635\n",
      "RMSE:  1822.0506584839059\n",
      "R2:  15.881345505844568\n",
      "\n",
      "Polynomial Regression Degree 2\n",
      "MSE:  1193017.5959715673\n",
      "RMSE:  1092.253448596784\n",
      "R2:  69.77138345232842\n",
      "\n",
      "Polynomial Regression Degree 3\n",
      "MSE:  1040487.744121782\n",
      "RMSE:  1020.0430109175701\n",
      "R2:  73.63617674557857\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(real_estate.drop('traffic_volume', axis=1),real_estate['traffic_volume'], test_size=0.2, random_state=44)\n",
    "\n",
    "# preprocessing with scaler\n",
    "# scaler = RobustScaler()\n",
    "scaler = MinMaxScaler()\n",
    "scaler_X_train = scaler.fit_transform(X_train)\n",
    "scaler_X_test = scaler.transform(X_test)\n",
    "\n",
    "# Linear Regression\n",
    "print('Linear Regression')\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print_performance(y_test, y_pred)\n",
    "\n",
    "# Lasso Regression\n",
    "print('\\nLasso Regression')\n",
    "grid = GridSearchCV(estimator=Lasso(),\n",
    "             param_grid={'alpha': alpha,\n",
    "                        'normalize':normalize})\n",
    "grid.fit(X_train, y_train)\n",
    "print(grid.best_params_)\n",
    "y_pred = grid.predict(X_test)\n",
    "print_performance(y_test, y_pred)\n",
    "\n",
    "# Ridge Regression\n",
    "print('\\nRidge Regression')\n",
    "grid = GridSearchCV(estimator=Ridge(),\n",
    "             param_grid={'alpha': alpha,\n",
    "                        'normalize':normalize})\n",
    "grid.fit(X_train, y_train)\n",
    "print(grid.best_params_)\n",
    "y_pred = grid.predict(X_test)\n",
    "print_performance(y_test, y_pred)\n",
    "\n",
    "# Polynomial Regression\n",
    "print('\\nPolynomial Regression Degree 2')\n",
    "y_pred2 = polynomial_regression(X_train, X_test, y_train)\n",
    "print_performance(y_test, y_pred2)\n",
    "print('\\nPolynomial Regression Degree 3')\n",
    "y_pred3 = polynomial_regression(X_train, X_test, y_train, 3)\n",
    "print_performance(y_test, y_pred3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Non-parametric Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN\n",
      "{'n_neighbors': 8, 'weights': 'distance'}\n",
      "MSE:  288368.27966347715\n",
      "RMSE:  536.9993292951837\n",
      "R2:  92.69333983011369\n"
     ]
    }
   ],
   "source": [
    "# knn regression\n",
    "print('KNN')\n",
    "grid = GridSearchCV(estimator=neighbors.KNeighborsRegressor(),\n",
    "             param_grid={'n_neighbors': n_neighbour,\n",
    "                        'weights': weights})\n",
    "grid.fit(X_train, y_train)\n",
    "print(grid.best_params_)\n",
    "y_pred = grid.predict(X_test)\n",
    "print_performance(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tree Models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression Tree\n",
      "{'max_depth': 12, 'min_samples_leaf': 12}\n",
      "MSE:  245245.0382504528\n",
      "RMSE:  495.2222109825576\n",
      "R2:  93.78599423300655\n",
      "\n",
      "Random Forest\n",
      "{'max_depth': 15, 'min_samples_leaf': 2, 'n_estimators': 75}\n",
      "MSE:  215914.07914906906\n",
      "RMSE:  464.66555623272643\n",
      "R2:  94.52918051847715\n"
     ]
    }
   ],
   "source": [
    "# regression tree\n",
    "print('Regression Tree')\n",
    "grid = GridSearchCV(estimator=DecisionTreeRegressor(),\n",
    "             param_grid={'max_depth': tree_max_depth,\n",
    "                        'min_samples_leaf': tree_min_split})\n",
    "grid.fit(X_train, y_train)\n",
    "print(grid.best_params_)\n",
    "y_pred = grid.predict(X_test)\n",
    "print_performance(y_test, y_pred)\n",
    "\n",
    "# random forest\n",
    "print('\\nRandom Forest')\n",
    "grid = GridSearchCV(estimator=RandomForestRegressor(),\n",
    "             param_grid={'n_estimators': forest_n_estimators,\n",
    "                         'max_depth': forest_max_depth,\n",
    "                         'min_samples_leaf': forest_min_split})\n",
    "grid.fit(X_train, y_train)\n",
    "print(grid.best_params_)\n",
    "y_pred = grid.predict(X_test)\n",
    "print_performance(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
