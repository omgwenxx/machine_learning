{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cooles Metric Vergleichs Zeugs juhuu ðŸ˜ŽðŸ˜ŽðŸ˜Ž"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_knn_scores(X_train, y_train, X_test, y_test, k_range, metric):\n",
    "    P, R, A, BA, ks = [], [], [], [], []\n",
    "    for k in k_range:\n",
    "        if k % 2 != 0:\n",
    "            knn = KNeighborsClassifier(n_neighbors=k, weights='distance', metric=metric)\n",
    "            knn.fit(X_train, y_train)\n",
    "            y_pred = knn.predict(X_test)\n",
    "\n",
    "            P.append(precision_score(y_test, y_pred))\n",
    "            R.append(recall_score(y_test, y_pred))\n",
    "            A.append(accuracy_score(y_test, y_pred))\n",
    "            BA.append(balanced_accuracy_score(y_test, y_pred))\n",
    "            ks.append(k)\n",
    "    \n",
    "    return P,R,A,BA, ks\n",
    "\n",
    "\n",
    "def get_svc_scores(X_train, y_train, X_test, y_test, C_range):\n",
    "    P, R, A, BA, Cs = [], [], [], [], []\n",
    "    for C in C_range:\n",
    "        svc = LinearSVC(random_state=42, C=C, dual=False)\n",
    "        svc.fit(X_train, y_train)\n",
    "        y_pred = svc.predict(X_test)\n",
    "\n",
    "        P.append(precision_score(y_test, y_pred))\n",
    "        R.append(recall_score(y_test, y_pred))\n",
    "        A.append(accuracy_score(y_test, y_pred))\n",
    "        BA.append(balanced_accuracy_score(y_test, y_pred))\n",
    "        Cs.append(C)\n",
    "    \n",
    "    return P,R,A,BA, Cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decide which dataset and scaling\n",
    "DATASET = 'num'\n",
    "\n",
    "SCALING = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load selected dataset\n",
    "if DATASET == 'cat':\n",
    "    df = pd.read_csv(\"../data/speeddating/speeddating_cat.csv\")\n",
    "else:\n",
    "    \n",
    "    df = pd.read_csv(\"../data/speeddating/speeddating_num.csv\")\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.2, random_state=44)\n",
    "\n",
    "X_train = train.drop(['match'], axis=1)\n",
    "y_train = train['match']\n",
    "X_test = test.drop(['match'], axis=1)\n",
    "y_test = test['match']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling if enabled\n",
    "if SCALING:\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate strings for labels and filenames\n",
    "sscaled = 'min-max-scaled' if SCALING else 'unscaled'\n",
    "dscaled = '_sc' if SCALING else ''\n",
    "sdata = 'numeric' if DATASET == 'num' else 'categorical'\n",
    "ddata = '_num' if DATASET == 'num' else '_cat'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # manhattan | euclidean | chebyshev\n",
    "metric = 'chebyshev'\n",
    "k_range = np.arange(1,29)\n",
    "\n",
    "P, R, A,BA,y = get_knn_scores(X_train, y_train, X_test, y_test, k_range, metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y, P)\n",
    "plt.plot(y, R)\n",
    "plt.plot(y, A)\n",
    "plt.plot(y, BA)\n",
    "plt.legend(['prc', 'rec', 'acc', 'bac'], loc='lower right')\n",
    "plt.title(f'{sscaled}, {sdata} data, {metric} distance')\n",
    "plt.xlabel('k')\n",
    "# plt.savefig(f'knn{ddata}{dscaled}_{metric}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_range = np.logspace(-4, -2, num=50)\n",
    "\n",
    "P,R,A,BA,y = get_svc_scores(X_train, y_train, X_test, y_test, C_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y, P)\n",
    "plt.plot(y, R)\n",
    "plt.plot(y, A)\n",
    "plt.plot(y, BA)\n",
    "plt.legend(['prc', 'rec', 'acc', 'bac'], loc='lower right')\n",
    "plt.title(f'{sscaled}, {sdata} data')\n",
    "plt.xlabel('C')\n",
    "plt.xscale('log')\n",
    "# plt.savefig(f'svc{ddata}{dscaled}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
