{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scikitplot as skplt\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'num'\n",
    "\n",
    "SCALING = False\n",
    "\n",
    "GRIDSEARCH = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATASET == 'cat':\n",
    "    df = pd.read_csv(\"../data/speeddating/speeddating_cat.csv\")\n",
    "else:\n",
    "    \n",
    "    df = pd.read_csv(\"../data/speeddating/speeddating_num.csv\")\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.2, random_state=44)\n",
    "\n",
    "X_train = train.drop(['match'], axis=1)\n",
    "y_train = train['match']\n",
    "X_test = test.drop(['match'], axis=1)\n",
    "y_test = test['match']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wave</th>\n",
       "      <th>d_age</th>\n",
       "      <th>samerace</th>\n",
       "      <th>importance_same_race</th>\n",
       "      <th>importance_same_religion</th>\n",
       "      <th>pref_o_attractive</th>\n",
       "      <th>pref_o_sincere</th>\n",
       "      <th>pref_o_intelligence</th>\n",
       "      <th>pref_o_funny</th>\n",
       "      <th>pref_o_ambitious</th>\n",
       "      <th>...</th>\n",
       "      <th>race_european/caucasian-american</th>\n",
       "      <th>race_latino/hispanic american</th>\n",
       "      <th>race_other</th>\n",
       "      <th>race_o_asian/pacific islander/asian-american</th>\n",
       "      <th>race_o_black/african american</th>\n",
       "      <th>race_o_european/caucasian-american</th>\n",
       "      <th>race_o_latino/hispanic american</th>\n",
       "      <th>race_o_other</th>\n",
       "      <th>gender_female</th>\n",
       "      <th>gender_male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7849.000000</td>\n",
       "      <td>7849.000000</td>\n",
       "      <td>7849.000000</td>\n",
       "      <td>7849.00000</td>\n",
       "      <td>7849.000000</td>\n",
       "      <td>7849.000000</td>\n",
       "      <td>7849.000000</td>\n",
       "      <td>7849.000000</td>\n",
       "      <td>7849.000000</td>\n",
       "      <td>7849.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7849.000000</td>\n",
       "      <td>7849.000000</td>\n",
       "      <td>7849.000000</td>\n",
       "      <td>7849.000000</td>\n",
       "      <td>7849.000000</td>\n",
       "      <td>7849.000000</td>\n",
       "      <td>7849.000000</td>\n",
       "      <td>7849.000000</td>\n",
       "      <td>7849.000000</td>\n",
       "      <td>7849.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>11.324118</td>\n",
       "      <td>3.766849</td>\n",
       "      <td>0.404892</td>\n",
       "      <td>3.78303</td>\n",
       "      <td>3.659702</td>\n",
       "      <td>22.307156</td>\n",
       "      <td>17.452342</td>\n",
       "      <td>20.316890</td>\n",
       "      <td>17.437718</td>\n",
       "      <td>10.702835</td>\n",
       "      <td>...</td>\n",
       "      <td>0.568353</td>\n",
       "      <td>0.079501</td>\n",
       "      <td>0.064212</td>\n",
       "      <td>0.240031</td>\n",
       "      <td>0.048796</td>\n",
       "      <td>0.566696</td>\n",
       "      <td>0.080647</td>\n",
       "      <td>0.063830</td>\n",
       "      <td>0.499809</td>\n",
       "      <td>0.500191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.975309</td>\n",
       "      <td>3.377976</td>\n",
       "      <td>0.490902</td>\n",
       "      <td>2.84508</td>\n",
       "      <td>2.804541</td>\n",
       "      <td>12.377736</td>\n",
       "      <td>7.039475</td>\n",
       "      <td>6.792136</td>\n",
       "      <td>6.083047</td>\n",
       "      <td>6.104028</td>\n",
       "      <td>...</td>\n",
       "      <td>0.495337</td>\n",
       "      <td>0.270536</td>\n",
       "      <td>0.245146</td>\n",
       "      <td>0.427129</td>\n",
       "      <td>0.215455</td>\n",
       "      <td>0.495563</td>\n",
       "      <td>0.272310</td>\n",
       "      <td>0.244465</td>\n",
       "      <td>0.500032</td>\n",
       "      <td>0.500032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>17.500000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>11.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>18.370000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>23.810000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>21.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.00000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 143 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              wave        d_age     samerace  importance_same_race  \\\n",
       "count  7849.000000  7849.000000  7849.000000            7849.00000   \n",
       "mean     11.324118     3.766849     0.404892               3.78303   \n",
       "std       5.975309     3.377976     0.490902               2.84508   \n",
       "min       1.000000     0.000000     0.000000               0.00000   \n",
       "25%       7.000000     1.000000     0.000000               1.00000   \n",
       "50%      11.000000     3.000000     0.000000               3.00000   \n",
       "75%      15.000000     5.000000     1.000000               6.00000   \n",
       "max      21.000000    32.000000     1.000000              10.00000   \n",
       "\n",
       "       importance_same_religion  pref_o_attractive  pref_o_sincere  \\\n",
       "count               7849.000000        7849.000000     7849.000000   \n",
       "mean                   3.659702          22.307156       17.452342   \n",
       "std                    2.804541          12.377736        7.039475   \n",
       "min                    1.000000           0.000000        0.000000   \n",
       "25%                    1.000000          15.000000       15.000000   \n",
       "50%                    3.000000          20.000000       18.370000   \n",
       "75%                    6.000000          25.000000       20.000000   \n",
       "max                   10.000000         100.000000       60.000000   \n",
       "\n",
       "       pref_o_intelligence  pref_o_funny  pref_o_ambitious  ...  \\\n",
       "count          7849.000000   7849.000000       7849.000000  ...   \n",
       "mean             20.316890     17.437718         10.702835  ...   \n",
       "std               6.792136      6.083047          6.104028  ...   \n",
       "min               0.000000      0.000000          0.000000  ...   \n",
       "25%              17.500000     15.000000          5.000000  ...   \n",
       "50%              20.000000     18.000000         10.000000  ...   \n",
       "75%              23.810000     20.000000         15.000000  ...   \n",
       "max              50.000000     50.000000         53.000000  ...   \n",
       "\n",
       "       race_european/caucasian-american  race_latino/hispanic american  \\\n",
       "count                       7849.000000                    7849.000000   \n",
       "mean                           0.568353                       0.079501   \n",
       "std                            0.495337                       0.270536   \n",
       "min                            0.000000                       0.000000   \n",
       "25%                            0.000000                       0.000000   \n",
       "50%                            1.000000                       0.000000   \n",
       "75%                            1.000000                       0.000000   \n",
       "max                            1.000000                       1.000000   \n",
       "\n",
       "        race_other  race_o_asian/pacific islander/asian-american  \\\n",
       "count  7849.000000                                   7849.000000   \n",
       "mean      0.064212                                      0.240031   \n",
       "std       0.245146                                      0.427129   \n",
       "min       0.000000                                      0.000000   \n",
       "25%       0.000000                                      0.000000   \n",
       "50%       0.000000                                      0.000000   \n",
       "75%       0.000000                                      0.000000   \n",
       "max       1.000000                                      1.000000   \n",
       "\n",
       "       race_o_black/african american  race_o_european/caucasian-american  \\\n",
       "count                    7849.000000                         7849.000000   \n",
       "mean                        0.048796                            0.566696   \n",
       "std                         0.215455                            0.495563   \n",
       "min                         0.000000                            0.000000   \n",
       "25%                         0.000000                            0.000000   \n",
       "50%                         0.000000                            1.000000   \n",
       "75%                         0.000000                            1.000000   \n",
       "max                         1.000000                            1.000000   \n",
       "\n",
       "       race_o_latino/hispanic american  race_o_other  gender_female  \\\n",
       "count                      7849.000000   7849.000000    7849.000000   \n",
       "mean                          0.080647      0.063830       0.499809   \n",
       "std                           0.272310      0.244465       0.500032   \n",
       "min                           0.000000      0.000000       0.000000   \n",
       "25%                           0.000000      0.000000       0.000000   \n",
       "50%                           0.000000      0.000000       0.000000   \n",
       "75%                           0.000000      0.000000       1.000000   \n",
       "max                           1.000000      1.000000       1.000000   \n",
       "\n",
       "       gender_male  \n",
       "count  7849.000000  \n",
       "mean      0.500191  \n",
       "std       0.500032  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       1.000000  \n",
       "75%       1.000000  \n",
       "max       1.000000  \n",
       "\n",
       "[8 rows x 143 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()#.to_csv('descr.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SCALING:\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Hyperparameters to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    }
   ],
   "source": [
    "# knn\n",
    "n_neighbour = np.arange(5, 26, 2) \n",
    "distance = ['manhattan', 'euclidean','chebyshev']\n",
    "\n",
    "# svc\n",
    "C = np.logspace(-5,5)\n",
    "\n",
    "# trees\n",
    "rf_n_estimators = np.arange(50, 151, 25)\n",
    "rf_max_depth = np.arange(15, 51, 5)\n",
    "rf_max_features = ['auto', 'log2']\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=False, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scores: MSE, RMSE, R2\n",
    "def print_performance(y_test, y_pred):\n",
    "    # Mean Squared Error\n",
    "    print(\"MSE: \", metrics.mean_squared_error(y_test,y_pred))\n",
    "    \n",
    "    print(\"RMSE: \", np.sqrt(metrics.mean_squared_error(y_test,y_pred)))\n",
    "    \n",
    "    # R2 is between 0 and 100 percent\n",
    "    # 0 indicates that the model explains none of the variability of the response data around its mean.\n",
    "    # 100 indicates that the model explains all the variability of the response data around its mean.\n",
    "    print(\"R2: \", metrics.r2_score(y_test,y_pred) * 100)\n",
    "\n",
    "# Metrics: various fancy metrics\n",
    "def print_metrics(y_test, y_pred):\n",
    "    results = pd.DataFrame(list(zip(y_test, y_pred)), \n",
    "                   columns =['Wage_test', 'Wage_prediction']) \n",
    "    \n",
    "    accuracy = results[\"Wage_test\"] - results[\"Wage_prediction\"]\n",
    "    accuracy = np.square(accuracy)\n",
    "    accuracy = np.sqrt(accuracy)\n",
    "    \n",
    "    print(\"# compare test and prediction\")\n",
    "    print(results)\n",
    "    \n",
    "    print(\"# bad predictions (over 100 difference)\")\n",
    "    print(results[(results[\"Wage_test\"] - results[\"Wage_prediction\"]) > 5])\n",
    "    \n",
    "    print(\"# span of data\")\n",
    "    span = results[\"Wage_test\"].max() - results[\"Wage_test\"].min()\n",
    "    print(span)\n",
    "    \n",
    "    print(\"# median accuracy\")\n",
    "    median = np.median(accuracy) \n",
    "    print(median)\n",
    "    \n",
    "    print(\"# percent deviation\")\n",
    "    percent = median / span * 100\n",
    "    percent_str = \"{:.4f}\".format(percent)\n",
    "    percent_str = percent_str + \" %\"\n",
    "    print(percent_str)\n",
    "    \n",
    "def show_roc(y_test, y_pred):\n",
    "    fpr, tpr, threshold = metrics.roc_curve(y_test, y_pred)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_grid(X_train, y_train, X_test):\n",
    "    print('KNN')\n",
    "    grid = GridSearchCV(estimator=KNeighborsClassifier(),cv=cv,\n",
    "                 param_grid={'n_neighbors': n_neighbour,\n",
    "                            'metric': metric})\n",
    "    grid.fit(X_train, y_train)\n",
    "    print(grid.best_params_)\n",
    "    return grid.predict(X_test)\n",
    "\n",
    "def knn(X_train, y_train, X_test):\n",
    "    knn = KNeighborsClassifier(n_neighbors = 19, weights= 'distance')\n",
    "    \n",
    "    if DATASET == 'cat':\n",
    "        if SCALING:\n",
    "            knn = KNeighborsClassifier(n_neighbors = 25, metric='euclidean')\n",
    "        else:\n",
    "            knn = KNeighborsClassifier(n_neighbors = 25, metric='manhattan')\n",
    "    else:\n",
    "        if SCALING:\n",
    "            knn = KNeighborsClassifier(n_neighbors = 23, metric='euclidean')\n",
    "        else:\n",
    "            knn = KNeighborsClassifier(n_neighbors = 21, metric='manhattan')\n",
    "            \n",
    "    knn.fit(X_train, y_train)\n",
    "    return knn.predict(X_test)\n",
    "\n",
    "\n",
    "if GRIDSEARCH:\n",
    "    y_test_knn = knn_grid(X_train, y_train, X_test)\n",
    "else:\n",
    "    y_test_knn = knn(X_train, y_train, X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print_performance(y_test, y_test_knn)\n",
    "# print_metrics(y_test, y_test_knn)\n",
    "# print(metrics.confusion_matrix(y_test, y_test_knn))\n",
    "# show_roc(y_test, y_test_knn)\n",
    "# \n",
    "P = precision_score(y_test, y_test_knn)\n",
    "R = recall_score(y_test, y_test_knn)\n",
    "A = accuracy_score(y_test, y_test_knn)\n",
    "BA = balanced_accuracy_score(y_test, y_test_knn)\n",
    "[P,R,A,BA]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def svc_grid(X_train, y_train, X_test):\n",
    "    print('\\nSVC')\n",
    "    grid = GridSearchCV(estimator=LinearSVC(random_state = 42, dual=False), cv=cv,\n",
    "                 param_grid={'C': C})\n",
    "    grid.fit(X_train, y_train)\n",
    "    print(grid.best_params_)\n",
    "    y_pred = grid.predict(X_test)\n",
    "    return y_pred\n",
    "\n",
    "def svc(X_train, y_train, X_test):\n",
    "    svc = LinearSVC(random_state = 42, dual=False)\n",
    "    \n",
    "    if DATASET == 'cat':\n",
    "        if SCALING:\n",
    "            svc = LinearSVC(random_state = 42, dual=False, C=0.004498432668969444)\n",
    "        else:\n",
    "            svc = LinearSVC(random_state = 42, dual=False, C=0.0071968567300115215)\n",
    "    else:\n",
    "        if SCALING:\n",
    "            svc = LinearSVC(random_state = 42, dual=False, C=0.004498432668969444)\n",
    "        else:\n",
    "            svc = LinearSVC(random_state = 42, dual=False, C=0.002811768697974231)\n",
    "            \n",
    "    svc.fit(X_train, y_train)\n",
    "    return svc.predict(X_test)\n",
    "\n",
    "\n",
    "if GRIDSEARCH:\n",
    "    y_test_svc = svc_grid(X_train, y_train, X_test)\n",
    "else:\n",
    "    y_test_svc = svc(X_train, y_train, X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 1.0, 1.0, 1.0]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print_performance(y_test, y_test_svc)\n",
    "# print_metrics(y_test, y_test_svc)\n",
    "# print(metrics.confusion_matrix(y_test, y_test_svc))\n",
    "# show_roc(y_test, y_test_svc)\n",
    "# \n",
    "P = precision_score(y_test, y_test_svc)\n",
    "R = recall_score(y_test, y_test_svc)\n",
    "A = accuracy_score(y_test, y_test_svc)\n",
    "BA = balanced_accuracy_score(y_test, y_test_svc)\n",
    "[P,R,A,BA]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest\n"
     ]
    }
   ],
   "source": [
    "def randomForest_grid(X_train, y_train, X_test):\n",
    "    print('\\nRandom Forest')\n",
    "    grid = GridSearchCV(estimator=RandomForestClassifier(),cv=cv,\n",
    "                 param_grid={'n_estimators': rf_n_estimators,\n",
    "                             'max_depth': rf_max_depth,\n",
    "                             'max_features': rf_max_features})\n",
    "    grid.fit(X_train, y_train)\n",
    "    print(grid.best_params_)\n",
    "    y_pred = grid.predict(X_test)\n",
    "    return y_pred\n",
    "\n",
    "def randomForest(X_train, y_train, X_test):\n",
    "    print('\\nRandom Forest')\n",
    "    \n",
    "    if DATASET == 'cat':\n",
    "        if SCALING:\n",
    "            rf = RandomForestClassifier(max_depth = 15, max_features='auto', n_estimators = 100)\n",
    "        else:\n",
    "            rf = RandomForestClassifier(max_depth = 40, max_features='auto', n_estimators = 150)\n",
    "    else:\n",
    "        if SCALING:\n",
    "            rf = RandomForestClassifier(max_depth = 25, max_features='auto', n_estimators = 150)\n",
    "        else:\n",
    "            rf = RandomForestClassifier(max_depth =40, max_features='auto', n_estimators = 150)\n",
    "    \n",
    "    rf.fit(X_train, y_train)\n",
    "    return rf.predict(X_test)\n",
    "\n",
    "\n",
    "if GRIDSEARCH:\n",
    "    y_test_rf = randomForest_grid(X_train, y_train, X_test)\n",
    "else:\n",
    "    y_test_rf = randomForest(X_train, y_train, X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 0.9772727272727273, 0.9961783439490446, 0.9886363636363636]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print_performance(y_test, y_test_rf)\n",
    "# print_metrics(y_test, y_test_rf)\n",
    "# print(metrics.confusion_matrix(y_test, y_test_svc))\n",
    "# show_roc(y_test, y_test_svc)\n",
    "# \n",
    "P = precision_score(y_test, y_test_rf)\n",
    "R = recall_score(y_test, y_test_rf)\n",
    "A = accuracy_score(y_test, y_test_rf)\n",
    "BA = balanced_accuracy_score(y_test, y_test_rf)\n",
    "[P,R,A,BA]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
